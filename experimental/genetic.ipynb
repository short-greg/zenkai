{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) create the optimization algorithm\n",
    "# 2) decide on th\n",
    "\n",
    "\n",
    "# x*1 + y* 2\n",
    "# lambda x, y: x * 1 + y * 2\n",
    "# Constaint = LTE(x=100, y=50) & GTE(x=0, y=0)\n",
    "# genetic = Genetic()\n",
    "# fitter.fit(func, constraint, x=20, y=30, const=['x'], penalty=-inf)\n",
    "# fitter.step( state=state)\n",
    "# 1) create the individual -> only x\n",
    "# 2) populate\n",
    "# 3) If not first\n",
    "#    get children\n",
    "#    cross over\n",
    "#    elitism\n",
    "# 3) mutate\n",
    "# 4) assess\n",
    "# 5) yield assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zenkai import tansaku\n",
    "import zenkai\n",
    "import torch\n",
    "\n",
    "x = 20\n",
    "y = 30\n",
    "\n",
    "\n",
    "objective = zenkai.FuncObjective(\n",
    "    lambda x, y: 2 * x + 2.5 * y \n",
    ")\n",
    "\n",
    "# how to convert to float\n",
    "individual = zenkai.Individual(x=20.0, y=30.0)\n",
    "population = individual.populate(10)\n",
    "\n",
    "mutator = tansaku.GaussianNoiser(0.2, 0.0)\n",
    "population = mutator(population)\n",
    "\n",
    "\n",
    "population = zenkai.Population(\n",
    "    x=population['x'].clamp(0, 30),\n",
    "    y=population['y'].clamp(0, 20)\n",
    ")\n",
    "\n",
    "\n",
    "print(population['x'])\n",
    "\n",
    "# # Add a \"Lambda\" constraint\n",
    "# LC(['x', 't'], lambda x, t: 2 * x + 3 * t < 4)\n",
    "# LC() + \n",
    "\n",
    "objective = zenkai.FuncObjective(lambda x, y: 3 * x + 5 * y, penalty=1000)\n",
    "assessor = tansaku.ObjectivePopAssessor(objective, ['x', 'y'])\n",
    "\n",
    "population = assessor(population)\n",
    "\n",
    "divider = tansaku.ProbDivider(6)\n",
    "parents1, parents2 = divider(population)\n",
    "\n",
    "print(parents1['x'], parents2['x'])\n",
    "crossover = tansaku.SmoothCrossOver()\n",
    "children =crossover(parents1, parents2)\n",
    "print(children['x'])\n",
    "\n",
    "elitism = tansaku.KBestElitism(2)\n",
    "children2 = elitism(population, children)\n",
    "print(children2['x'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from zenkai import tansaku\n",
    "from zenkai.kaku import Assessment\n",
    "import torch\n",
    "from functools import partial\n",
    "import zenkai\n",
    "\n",
    "class GeneticAlgorithm(zenkai.Itadaki):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.divider = tansaku.ProbDivider(8)\n",
    "        self.elitism = tansaku.KBestElitism(2)\n",
    "        self.crossover = tansaku.SmoothCrossOver()\n",
    "        self.mutator = tansaku.GaussianNoiser(0.5, 0.0)\n",
    "        self.n = 10\n",
    "        self.iterations = 100\n",
    "\n",
    "    def optim_iter(self, objective: zenkai.Objective, **kwargs) -> typing.Iterator[Assessment]:\n",
    "        \n",
    "        assessor = tansaku.ObjectivePopAssessor(objective, ['x', 'y'])\n",
    "\n",
    "        if i == 0:\n",
    "            individual = zenkai.Individual(**kwargs)\n",
    "            population = individual.populate(self.n)\n",
    "            population = self.mutator(population)\n",
    "\n",
    "        while i < self.iterations:\n",
    "            \n",
    "            if i > 0:\n",
    "                parents1, parents2 = self.divider(population)\n",
    "                \n",
    "                children = self.crossover(parents1, parents2)\n",
    "                children = self.mutator(children)\n",
    "                population = self.elitism(population, children)\n",
    "            \n",
    "            population = population.apply(partial(torch.clamp, min=0))\n",
    "\n",
    "            population = assessor(population)\n",
    "            \n",
    "            yield population.stack_assessments()\n",
    "            i += 1\n",
    "\n",
    "\n",
    "objective = zenkai.FuncObjective(\n",
    "    lambda x, y: torch.abs(2 * x + 3 * y), constraint=zenkai.LTE(y=5, x=10) + zenkai.GTE(y=0, x=0), penalty=0, maximize=True\n",
    ")\n",
    "\n",
    "\n",
    "genetic_algorithm = GeneticAlgorithm()\n",
    "\n",
    "for assessment in genetic_algorithm.optim_iter(objective, x=3.0, y=4.0):\n",
    "    print(assessment)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "from zenkai import tansaku\n",
    "import zenkai\n",
    "from zenkai.kaku import Assessment, State\n",
    "import torch\n",
    "from functools import partial\n",
    "\n",
    "class GeneticAlgorithm(zenkai.Itadaki):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.divider = tansaku.ProbDivider(8, 2)\n",
    "        self.elitism = tansaku.KBestElitism(2, 2)\n",
    "        self.crossover = tansaku.SmoothCrossOver()\n",
    "        self.mutator = tansaku.GaussianNoiser(0., 0.0)\n",
    "        self.n = 10\n",
    "        self.iterations = 100\n",
    "\n",
    "    def optim_iter(self, objective: zenkai.Objective, **kwargs) -> typing.Iterator[Assessment]:\n",
    "        \n",
    "        assessor = tansaku.ObjectivePopAssessor(objective, ['w', 'b'], reduce_from=2)\n",
    "\n",
    "        if i == 0:\n",
    "            individual = zenkai.Individual(**kwargs)\n",
    "            population = individual.populate(self.n)\n",
    "            population = self.mutator(population)\n",
    "\n",
    "        while i < self.iterations:\n",
    "            \n",
    "            if i > 0:\n",
    "                parents1, parents2 = self.divider(population)\n",
    "                \n",
    "                children = self.crossover(parents1, parents2)\n",
    "                children = self.mutator(children)\n",
    "                population = self.elitism(population, children)\n",
    "            \n",
    "            population = assessor(population)\n",
    "            yield population.stack_assessments()\n",
    "            i += 1\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "from zenkai import ThLoss, IO\n",
    "\n",
    "base_linear = nn.Linear(32, 8)\n",
    "base_network = nn.Sequential(\n",
    "    base_linear,\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "optimize_linear = nn.Linear(32, 8)\n",
    "optimize_network = nn.Sequential(\n",
    "    optimize_linear,\n",
    "    nn.ReLU()\n",
    ")\n",
    "\n",
    "x = torch.rand(128, 32)\n",
    "t = base_network(x)\n",
    "\n",
    "objective = zenkai.NNLinearObjective(\n",
    "    optimize_linear, optimize_network, ThLoss('MSELoss'), IO(x), IO(t)\n",
    ")\n",
    "\n",
    "# objective = tansaku.FuncObjective(\n",
    "#     lambda x, y: torch.abs(2 * x + 3 * y), constraint=tansaku.LTE(y=5, x=10) + tansaku.GTE(y=0, x=0), penalty=0, maximize=True\n",
    "# )\n",
    "\n",
    "\n",
    "genetic_algorithm = GeneticAlgorithm()\n",
    "\n",
    "for assessment in genetic_algorithm.optim_iter(objective, w=optimize_linear.weight, b=optimize_linear.bias):\n",
    "    print(assessment)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:15<00:00, 30.62it/s, loss=2.14, Epoch=0/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.90it/s, loss=1.78, Epoch=1/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.33it/s, loss=1.32, Epoch=2/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.14it/s, loss=1.02, Epoch=3/100] \n",
      "100%|██████████| 469/469 [00:13<00:00, 34.14it/s, loss=0.776, Epoch=4/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 34.01it/s, loss=0.642, Epoch=5/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.91it/s, loss=0.568, Epoch=6/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 34.07it/s, loss=0.517, Epoch=7/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.71it/s, loss=0.466, Epoch=8/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 34.20it/s, loss=0.445, Epoch=9/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.74it/s, loss=0.396, Epoch=10/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.58it/s, loss=0.408, Epoch=11/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.08it/s, loss=0.38, Epoch=12/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 33.08it/s, loss=0.371, Epoch=13/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.89it/s, loss=0.362, Epoch=14/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.52it/s, loss=0.36, Epoch=15/100] \n",
      "100%|██████████| 469/469 [00:13<00:00, 33.64it/s, loss=0.36, Epoch=16/100] \n",
      "100%|██████████| 469/469 [00:13<00:00, 34.59it/s, loss=0.334, Epoch=17/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 34.02it/s, loss=0.329, Epoch=18/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.89it/s, loss=0.326, Epoch=19/100]\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.71it/s, loss=0.319, Epoch=20/100]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.98it/s, loss=0.31, Epoch=21/100] \n",
      "100%|██████████| 469/469 [00:15<00:00, 29.65it/s, loss=0.308, Epoch=22/100]\n",
      "100%|██████████| 469/469 [00:15<00:00, 29.72it/s, loss=0.331, Epoch=23/100]\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.17it/s, loss=0.319, Epoch=24/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 34.37it/s, loss=0.291, Epoch=25/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.32it/s, loss=0.29, Epoch=26/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.56it/s, loss=0.296, Epoch=27/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.31it/s, loss=0.314, Epoch=28/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.49it/s, loss=0.295, Epoch=29/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.00it/s, loss=0.307, Epoch=30/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.57it/s, loss=0.308, Epoch=31/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.68it/s, loss=0.309, Epoch=32/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.90it/s, loss=0.288, Epoch=33/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.07it/s, loss=0.304, Epoch=34/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.72it/s, loss=0.298, Epoch=35/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.50it/s, loss=0.294, Epoch=36/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.43it/s, loss=0.303, Epoch=37/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.56it/s, loss=0.305, Epoch=38/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.14it/s, loss=0.304, Epoch=39/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.31it/s, loss=0.267, Epoch=40/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.61it/s, loss=0.287, Epoch=41/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.97it/s, loss=0.295, Epoch=42/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.73it/s, loss=0.262, Epoch=43/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.18it/s, loss=0.259, Epoch=44/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.81it/s, loss=0.27, Epoch=45/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.54it/s, loss=0.29, Epoch=46/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.77it/s, loss=0.303, Epoch=47/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.85it/s, loss=0.289, Epoch=48/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.11it/s, loss=0.243, Epoch=49/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.85it/s, loss=0.27, Epoch=50/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 33.19it/s, loss=0.281, Epoch=51/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.09it/s, loss=0.298, Epoch=52/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.94it/s, loss=0.258, Epoch=53/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.74it/s, loss=0.236, Epoch=54/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.81it/s, loss=0.253, Epoch=55/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.29it/s, loss=0.284, Epoch=56/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.15it/s, loss=0.239, Epoch=57/100]\n",
      "100%|██████████| 469/469 [00:15<00:00, 30.46it/s, loss=0.263, Epoch=58/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.88it/s, loss=0.265, Epoch=59/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.78it/s, loss=0.238, Epoch=60/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.26it/s, loss=0.259, Epoch=61/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.07it/s, loss=0.268, Epoch=62/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.02it/s, loss=0.246, Epoch=63/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.29it/s, loss=0.245, Epoch=64/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.61it/s, loss=0.251, Epoch=65/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.65it/s, loss=0.247, Epoch=66/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.08it/s, loss=0.244, Epoch=67/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.55it/s, loss=0.238, Epoch=68/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.07it/s, loss=0.25, Epoch=69/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.36it/s, loss=0.258, Epoch=70/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.86it/s, loss=0.222, Epoch=71/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.23it/s, loss=0.23, Epoch=72/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 33.35it/s, loss=0.24, Epoch=73/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 33.08it/s, loss=0.26, Epoch=74/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.53it/s, loss=0.243, Epoch=75/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.21it/s, loss=0.243, Epoch=76/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.17it/s, loss=0.245, Epoch=77/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.11it/s, loss=0.252, Epoch=78/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.89it/s, loss=0.23, Epoch=79/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.94it/s, loss=0.244, Epoch=80/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.93it/s, loss=0.243, Epoch=81/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.28it/s, loss=0.218, Epoch=82/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.92it/s, loss=0.232, Epoch=83/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.86it/s, loss=0.232, Epoch=84/100]\n",
      "100%|██████████| 469/469 [00:13<00:00, 33.64it/s, loss=0.22, Epoch=85/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.79it/s, loss=0.244, Epoch=86/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.78it/s, loss=0.236, Epoch=87/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.13it/s, loss=0.207, Epoch=88/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.41it/s, loss=0.218, Epoch=89/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.21it/s, loss=0.217, Epoch=90/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.64it/s, loss=0.22, Epoch=91/100] \n",
      "100%|██████████| 469/469 [00:14<00:00, 32.57it/s, loss=0.213, Epoch=92/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.20it/s, loss=0.223, Epoch=93/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 33.11it/s, loss=0.238, Epoch=94/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.42it/s, loss=0.226, Epoch=95/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 31.90it/s, loss=0.233, Epoch=96/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.66it/s, loss=0.216, Epoch=97/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.44it/s, loss=0.217, Epoch=98/100]\n",
      "100%|██████████| 469/469 [00:14<00:00, 32.73it/s, loss=0.22, Epoch=99/100] \n",
      "100%|██████████| 1/1 [00:00<00:00,  1.15it/s, loss=0.221, Epoch=0/1]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'x'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb Cell 7\u001b[0m line \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m testing_dataset \u001b[39m=\u001b[39m MNIST(\u001b[39m'\u001b[39m\u001b[39m~/development/datasets/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m, transform, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m record \u001b[39m=\u001b[39m sensei\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m     learner, sensei\u001b[39m.\u001b[39;49mDLMaterial\u001b[39m.\u001b[39;49mload(training_dataset, \u001b[39m128\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m),  \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     sensei\u001b[39m.\u001b[39;49mDLMaterial\u001b[39m.\u001b[39;49mload(testing_dataset, \u001b[39m10000\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m), \u001b[39m100\u001b[39;49m, use_io\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/shortg/development/zenkaibase/zenkai/experimental/genetic.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchx/lib/python3.8/site-packages/sensei/teaching.py:272\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(learner, training_material, testing_material, n_epochs, use_io, window, training_assistants, testing_assistants, trainer_name, tester_name, record)\u001b[0m\n\u001b[1;32m    270\u001b[0m     trainer\u001b[39m.\u001b[39mteach()\n\u001b[1;32m    271\u001b[0m \u001b[39mif\u001b[39;00m tester \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 272\u001b[0m     tester\u001b[39m.\u001b[39;49mteach()\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m record\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchx/lib/python3.8/site-packages/sensei/base.py:248\u001b[0m, in \u001b[0;36mTeacher._teach_with_assistance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_teach_with_assistance\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    247\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assistants\u001b[39m.\u001b[39massist(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 248\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_teach(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_assistants\u001b[39m.\u001b[39massist(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname, \u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/pytorchx/lib/python3.8/site-packages/sensei/teaching.py:170\u001b[0m, in \u001b[0;36mValidator.teach\u001b[0;34m(self, override_learner, override_material)\u001b[0m\n\u001b[1;32m    168\u001b[0m         pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m    169\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress\u001b[39m.\u001b[39madv()\n\u001b[0;32m--> 170\u001b[0m         state\u001b[39m.\u001b[39;49mspawn()\n\u001b[1;32m    172\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogress\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m TeachingStatus\u001b[39m.\u001b[39mFINISH_EPOCH\n",
      "File \u001b[0;32m~/development/zenkaibase/zenkai/zenkai/kaku/state.py:378\u001b[0m, in \u001b[0;36mState.spawn\u001b[0;34m(self, spawn_logs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    375\u001b[0m     \u001b[39m# loop over all keys\u001b[39;00m\n\u001b[1;32m    376\u001b[0m     \u001b[39mfor\u001b[39;00m k2, v2 \u001b[39min\u001b[39;00m v\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    377\u001b[0m         \u001b[39m# add the data if it is supposed to be kept\u001b[39;00m\n\u001b[0;32m--> 378\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_keep[k][k2]:\n\u001b[1;32m    379\u001b[0m             \u001b[39mif\u001b[39;00m k \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m data:\n\u001b[1;32m    380\u001b[0m                 data[k] \u001b[39m=\u001b[39m {}\n",
      "\u001b[0;31mKeyError\u001b[0m: 'x'"
     ]
    }
   ],
   "source": [
    "from zenkai.kikai.experimental import genetic\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import sensei\n",
    "import torch\n",
    "\n",
    "learner = genetic.GeneticNetwork()\n",
    "learner.to('cuda')\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    ")\n",
    "training_dataset = MNIST('~/development/datasets/', True, transform, download=True)\n",
    "testing_dataset = MNIST('~/development/datasets/', False, transform, download=True)\n",
    "torch.device(\"cuda\")\n",
    "\n",
    "record = sensei.train(\n",
    "    learner, sensei.DLMaterial.load(training_dataset, 128, True),  \n",
    "    sensei.DLMaterial.load(testing_dataset, 10000, True), 100, use_io=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
